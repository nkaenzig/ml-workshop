{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workshop\n",
    "## Ejercicio - Breast Cancer Diagnosis\n",
    "Dataset: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data<br>\n",
    "Tarea: Preprocesamiento de un conjunto de datos de cancer de mama y entrenamiento de un modelo de Machine Learning para diagnosticar la enfermedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# | remove max column restriction for printing DataFrames (default=20)\n",
    "pd.options.display.max_columns = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../Datasets/breast-cancer.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1a) </b> Lea el archivo CSV <i> breast-cancer.csv </i> con pandas y guárdelo en un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1b) </b> Hay columnas que no necesitamos para el entrenamiento del modelo?  Si es el caso, eliminalos (Hint: <code>DataFrame.drop()</code>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1c) </b> La columna \"diagnosis\" indica si una persona tiene cancer ('M') o no ('B'). Vamos a usar esta columna como label para entrenar nuestro modelo. Pero para usar las funciones de scikit-learn, necesitamos convertirlo a una columna numerica, i.e. 'B' -> 0, 'M' -> 1. <br>(Hint: <code>df['diagnosis'] = df['diagnosis'].map(...)</code> https://pandas.pydata.org/pandas-docs/stable//reference/api/pandas.Series.map.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1d) </b> Calculando los contados de los dos clases 'B' & 'M' observamos que hay mas ejemplos de la clase 'B' (personas sanas) que de la clase 'M' (personas con cancer). Unos modelos de Machine Learning no funcionan bien si el training set es desbalanceado. Usa el siguiente codigo para balancear el dataset y trata de entenderlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | calcular los contados de los dos clases\n",
    "print(df['diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | shuffle\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# | class balancing\n",
    "g = df.groupby('diagnosis')\n",
    "df = g.apply(lambda x: x.sample(g.size().min())).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1e) </b> Divide el DataFrame en dos DataFrames nuevos <code>X, y</code>, donde <code>y</code> contiene los Labels (columna \"diagnosis), y <code>X</code> las otras columnas (Features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"diagnosis\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1f) </b> Aplica estandarización a los features (X). Recuerde: El objetivo de la estandarización es cambiar los valores de las columnas numéricas en el conjunto de datos a una escala común. (Hint: <code>df.mean(), df.std()</code>)<br>\n",
    "\\begin{equation*}\n",
    "x = \\frac{x-\\mu}{\\sigma}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1f) </b> Divide el dataset en un training set (70%) y un test set (30%). Puedes usar la funcion <code>train_test_split()</code> de scikit-learn o hacerlo de forma manual con Indexing https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html. <br>\n",
    "\n",
    "Al fin deberias tener cuatro nuevos variables: <br>\n",
    "- X_train : Training features\n",
    "- y_train : Training labels\n",
    "- X_test : Test features\n",
    "- y_test : Test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2a) </b> Ahora los datos estan listos para entrenar nuestro primero modelo. Entrena un modelo Random Forest, usando la clase <code>RandomForestClassifier</code> de scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2b) </b> Usa <code>model.predict()</code> para calcular las predicciones en el test-set. Despues calcula el porcentaje de las predicciones correctas (\"Accuracy\"). (Hint: Puedes usar la funcion <code>accuracy_score</code> de scikit-learn https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html, o calcularlo de forma manual). Si te da un valor mayor a 90%, has hecho todo bien, si te da un valor menor revisa tu codigo o pregunta el mentor antes de seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2c) </b> Evalua tu modelo usando <code>cross_val_score(..., scoring='accuracy')</code> con 5 dataset splits (cv=5), y calcula la media y la desviacion estándar de los resultados (con numpy) (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html). Defina una nueva variable de modelo e inicialícela con un nuevo RandomForestClassifier antes de usar <code>cross_val_score</code>, para no usar el mismo modelo que ya has entrenado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection & Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2d) </b> Compara los modelos <code>RandomForestClassifier, KNeighborsClassifier, SVC</code>. Cual funciona mejor? Intenta entrenarlas con diferentes parametros y observa si mejoran los resultados.<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html <br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html <br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "Hint: En el siguiente encontrarás los parametros mas relevantes de estos modelos:\n",
    "\n",
    "- RandomForestClassifier(): n_estimators, criterion, max_depth\n",
    "- KNeighborsClassifier(): n_neighbors, weights, algorithm\n",
    "- SVC(): C, kernel, degree, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2e) </b> Seguramente te has dado cuenta que hay muchos diferentes combinaciones posibles de parametros. Cambiarlos a mano cada vez que se entrena un nuevo modelo no es muy efectivo. Scikit-learn tiene una funcion que ayuda a accelerar este processo: <code>GridSearchCV</code> hace una búsqueda exhaustiva sobre los valores de parámetros especificados.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "Hint:\n",
    "Es importante no escoger demasiados parametros. Para cada combinacion de parametros se entrena un nuevo modelo, si lo corremos con milles de combinaciones diferentes, este proceso puede demorar mucho tiempo, dependiendo del modelo y del tamano del dataset.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
